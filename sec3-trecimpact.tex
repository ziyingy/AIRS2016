\section{Ties in TREC Experimentation}
\label{sec-trecimpact}

\myparagraph{TREC Resources}

In this section we examine the role that ties may have had on past
TREC evaluations.
The primary resource we make use of are the $103$ runs submitted as
part of the 2008 TREC7 Ad-Hoc experimentation round, see
{\small\url{trec.nist.gov}}, and {\citet{harman05trecbook}} for a
broad overview.
Each run is a list of $1{,}000$ responses from that system for each
of $50$ topics, with each row in the run file including fields for
{\emph{docnum}}, {\emph{rank}}, and {\emph{score}}.
There are thus three possible ways that each run could be
interpreted:
\begin{itemize}
\item
by the line number ordering implicit in the presentation of the run;
\item
by (increasing, or at least, non-decreasing) values in the
{\emph{rank}} field;
\item
by (decreasing, or at least, non-increasing) values in the
{\emph{score}} field.
\end{itemize}
Line numbers are unique within each system-topic combination, and do
not admit ties, but both ranks and scores might provide ties in runs.
To explore the prevalence of ties, the TREC7 Ad-Hoc runs were
analyzed.
Somewhat surprisingly, we discovered that there were $254$ instances
in the archived runs where scores were increasing rather than
non-increasing, and that five systems were affected by this
inconsistency.
The primary reason appears to be incorrect sorting of scores when
exponential formatting is being used.
For example, in the run {\tt{bbn1}}, for topic $355$, the
second-to-last score in the run is {\tt{-1.37}}; and final score is
{\tt{-7.763e-05}}.
In fact, that last document's correct position is some $700$
locations higher, at rank $304$, the rank that row was labelled with.
When rank ordering was similarly checked the situation was even more
confused, and $7.3$\% of the documents in the archived runs
($358{,}631$ entries in total) were misordered according to their
stated ranks.
That is, the supplied document ordering in the runs corresponds to
neither increasing rank nor to non-decreasing score.

\begin{table}[t!]
\centering
\input{tbl-trec7-ties.tex}
\renewcommand{\tabcolsep}{0.5em}
\caption{Ties occuring in $103$ TREC7 Ad-Hoc runs after score-based
resorting: the percentage of systems, system/topic combinations, and
documents that include tied scores; and the corresponding percentages 
of score-rank contraditions.
There are a total of $103$ systems, $103\times50$ system-topic combinations,
and $103\times50\times1000$ documents.
\label{tbl-trec7-ties}}
\end{table}

To resolve this apparent mislabeling, we re-sorted all of the TREC7
submissions, taking care to treat the exponential formats correctly.
We used decreasing numeric score as the primary key, and then
increasing rank as a secondary key.
This is guaranteed to give rise to runs in which there are no
score-based out-of-order items.
We then counted the occurrences of score ties at the document, topic,
and system level; and the occurrence of rank contradictions, where a
``contradiction'' is a pair of adjacent documents that when sorted by
score have ranks that indicate the opposite ordering.
Table~\ref{tbl-trec7-ties} shows the results of this processing.
As can be seen, $14$\% of the documents in the runs have the same
score as their predecessor document in that run, a fact that provides
the motivation for our exploration of how they should be handled;
and, of equal concern, it is clear that a further $1.4$\% of the
documents cannot be placed in a manner that is consistent with both
their assigned score and their assigned rank, with seven of the $103$
systems affected.
We can only assume that the cause of the latter issue was programming
errors at the time the runs were created by the corresponding
research groups.

\myparagraph{Ties in TREC7}

The primary metric used in TREC7 was average precision, AP.
Worked with te re-sorted runs, and looking solely at the system
scores, {\alistair{more...}}

\begin{figure}[t!]
\centering
\rule{0.5mm}{40mm}
\caption{The extent of the imprecision in AP scores arising from ties
in runs.
{\alistair{Need one of the graphs we had many weeks ago, showing that
max score for one system might exceed assigned trec\_eval score for a
supposedly ``better'' system.}}
\label{fig-trec7-ap-scores}}
\end{figure}

Figure~\ref{fig-trec7-ap-scores} shows {\alistair{more...}}

\myparagraph{Ties in Other Years}

{\alistair{Brief summary (no tables or graphs) of some other TREC
rounds.}}
{\alistair{TREC8: Similar percentages of ties and score/rank
contradictions, and ditto after resorting.}}
